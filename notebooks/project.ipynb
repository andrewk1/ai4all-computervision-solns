{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Project\n",
    "\n",
    "For our project we will implement **logistic regression** and train it to classify locations of high poverty and low poverty using satellite imagery of Uganda. This will be a complete machine learning experiment, using a training, validation, and testing set, so we will implement **cross validation** as well.\n",
    "\n",
    "You will need to use, and fix, the functions in the following files:\n",
    "\n",
    "### models.py [link](http://localhost:8888/edit/project/models.py)\n",
    "\n",
    "Contains **classes** for **LogisticRegression** and two **baseline** models: One that guesses randomly, and one that always guesses the most frequent class.\n",
    "\n",
    "You will **not** need to change any code in this file, but you **will** need to instantiate these classes and call their **train** and **predict** methods in [model_helpers.py](http://localhost:8888/edit/notebooks/project/model_helpers.py).\n",
    "\n",
    "### metrics.py [link](http://localhost:8888/edit/project/metrics.py)\n",
    "\n",
    "Provides a set of functions for judging how well your model performs given some data. The metrics include accuracy, f1 score, and area under the curve (auc).\n",
    "\n",
    "You will **not** need to change any code in this file, but you **will** need to use these functions in the __cross_validation__ function in [experiment_helpers.py](http://localhost:8888/edit/notebooks/project/experiment_helpers.py).\n",
    "\n",
    "### model_helpers.py [link](http://localhost:8888/edit/project/model_helpers.py)\n",
    "\n",
    "Contains training and prediction functions used by our **Logistic Regression** model.\n",
    "\n",
    "**Your job is to complete the functions in this file! **\n",
    "\n",
    "### experiment_helpers.py [link](http://localhost:8888/edit/project/experiment_helpers.py)\n",
    "\n",
    "Contains code for spliting up the data into **training** and **validation** sets, for both the **trucks and planes** and **Uganda** datasets. Also contains code for **cross validation**.\n",
    "\n",
    "** Your job is to complete the functions in this file! **\n",
    "\n",
    "## Project Instructions\n",
    "\n",
    "This notebook provides more moving parts, and more chances to be creative with how your design your expriments. As a bit of guidance, we recommend doing things in this order:\n",
    "\n",
    "(1) Look over the files [models.py](http://localhost:8888/edit/notebooks/project/models.py) and [metrics.py](http://localhost:8888/edit/notebooks/project/metrics.py). You do **not** need to understand every line of code, but try to get a general sense of the **functions** and **classes** contained in these files. Can you describe the inputs and outputs to each function?\n",
    "\n",
    "(2) Complete the \"create_trucksplanes_dataset\" function in [experiment_helpers.py](http://localhost:8888/edit/notebooks/project/experiment_helpers.py). This function is **necessary** for creating the Trucks and Planes dataset that we can use to get a general sense for how logistic regression works.\n",
    "\n",
    "(3) Complete the \"predict_probability\" function in [model_helpers.py](http://localhost:8888/edit/notebooks/project/model_helpers.py). This function is **necessary** for making predictions, and also training your model.\n",
    "\n",
    "(4) Complete the \"sgd\" function in [model_helpers.py](http://localhost:8888/edit/notebooks/project/model_helpers.py). This function is **necessary** for training your model.\n",
    "\n",
    "(5) **Optional:** Run the **Unit Testing** block in this notebook to see if there are any problems with \"predict_probability\" and \"sgd\". Don't worry about \"batch_sgd\" for now!\n",
    "\n",
    "(6) Complete the **cross_validation** function in [experiment_helpers.py](http://localhost:8888/edit/notebooks/project/experiment_helpers.py). This is the \"main function\" for the entire project! When its complete, you can start getting experimental results on your training, validation, and testing sets!\n",
    "\n",
    "(7) Run the first few blocks of this notebook to get results on the **Trucks and Planes** dataset.\n",
    "\n",
    "(8) **Optional:** Complete the \"batch_sgd\" function in [model_helpers.py](http://localhost:8888/edit/notebooks/project/model_helpers.py). TYouu can complete the project without this function. But if you can figure it out, you may get better results!\n",
    "\n",
    "(9) Time to do some real Poverty Mapping! Go back and complete the \"create_uganda_dataset\" in [experiment_helpers.py](http://localhost:8888/edit/notebooks/project/experiment_helpers.py).\n",
    "\n",
    "(10) Run the **Classifying Poverty** block in this notebook. Adjust your hyperparameters, and improve your results.\n",
    "\n",
    "(11) Run the final cell and see how well your model does on the Uganda test set!\n",
    "\n",
    "### Remember: You must restart the Kernel (top bar) in order for your changes to other files to take effect! (Kernel >> Restart & Clear Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logistic_regression_utils import *\n",
    "from utils.model_testers import *\n",
    "\n",
    "from project.models import ALL_MODELS\n",
    "from project.experiment_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Train-Test Split\n",
    "\n",
    "After creating your datasets, run the code below to see the shape of your data matrices. Are you satisfied with how you've divided examples between the **training** and **validation** sets? How many **features** does each of your datasets have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Testing\n",
    "\n",
    "In big software projects like this, engineers usually do **Unit Tests**: We take small units of code and test them on a few inputs and outputs, to make sure their working. After implementing your model helper functions. Try running the tests below to see if you have any bugs you might have overlooked:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Extracting Trucks and Planes Dataset ###\n",
      "Extracted 500 of 4184 histograms\n",
      "Extracted 1000 of 4184 histograms\n",
      "Extracted 1500 of 4184 histograms\n",
      "Extracted 2000 of 4184 histograms\n",
      "Extracted 2500 of 4184 histograms\n",
      "Extracted 3000 of 4184 histograms\n",
      "Extracted 3500 of 4184 histograms\n",
      "Extracted 4000 of 4184 histograms\n",
      "Extracted 4184 of 4184 histograms\n",
      "Done!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-db17925aa827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_trucksplanes_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trucks and Planes Dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shape of training data: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shape of validation data: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/stanford-ai4all-vision/notebooks/project/experiment_helpers.py\u001b[0m in \u001b[0;36mcreate_trucksplanes_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m## END YOUR CODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_uganda_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_train' is not defined"
     ]
    }
   ],
   "source": [
    "data_train, labels_train, data_validation, labels_validation = create_trucksplanes_dataset()\n",
    "print(\"Trucks and Planes Dataset\")\n",
    "print(\"shape of training data: {}\".format(np.shape(data_train)))\n",
    "print(\"shape of validation data: {}\".format(np.shape(data_validation)))\n",
    "\n",
    "data_train, labels_train, data_validation, labels_validation = create_uganda_dataset()\n",
    "print(\"Uganda Dataset\")\n",
    "print(\"shape of training data: {}\".format(np.shape(data_train)))\n",
    "print(\"shape of validation data: {}\".format(np.shape(data_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if the predict_probability function returns the right probabilities.\n",
    "test_predict_probability()\n",
    "# checks if the sgd function returns the right weights.\n",
    "test_sgd()\n",
    "# checks if the batch_sgd function returns the right weights.\n",
    "test_batch_sgd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Trucks and Planes\n",
    "\n",
    "Before testing your code on a hard problem (like poverty mapping), it makes sense to make sure everything works for an easier one first. Run your implementation of **cross validation** below to launch your experiment on the **Trucks and Planes** dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trucks_and_planes_hyperparameters = cross_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does your model performance look on the validation set? When you're satisfied with its results, retrain your model using the **best hyperparameters** you found by running the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_t, y_t, X_v, y_v = create_trucksplanes_dataset()\n",
    "data = np.concatenate([X_t, X_v], axis=0)\n",
    "labels = np.concatenate([y_t, y_v])\n",
    "_ = compute_final_results(best_trucks_and_planes_hyperparameters, ALL_MODELS, data=data, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Poverty\n",
    "\n",
    "Now it's time to see how our techniques perform for mapping poverty! Launch the next cell to do a complete machine learning experiment on the **Uganda Satellite Dataset** we downloaded at the beginning of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_uganda_hyperparameters = cross_validation(use_satellite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Your Results\n",
    "\n",
    "Getting your code to run and giving you an experimental result is only the first step! Its very important to experiment with different **hyperparameters** such as the **learning rate** and **regularization rate** to make sure model does as well as possible.\n",
    "\n",
    "**Consider the following questions, and use them to improve your experimental design:**\n",
    "\n",
    "* Which hyperparameters make the biggest difference? If you keep adjusting them, will you get a better result?\n",
    "* Which metrics should we use to assess our model, and why? Does it make sense to combine different metrics during cross validation?\n",
    "* Is your model overfitting? Can you avoid this by reducing the number of features, or making better use of your training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = compute_final_results(\n",
    "    best_uganda_hyperparameters, ALL_MODELS, use_satellite = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Poverty\n",
    "\n",
    "The final step is to run your model for each location we've surveyed in Uganda and predict its probability of poverty. Locations with higher probability of being impoverished are shown in red. How does your map predict to the labeled data and the baseline models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uganda_map(trained_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
